{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish environment\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and test data (max nrows = 55M)\n",
    "raw_train =  pd.read_csv('input_data/train.csv', nrows = 2_000_000)\n",
    "raw_test =  pd.read_csv('input_data/test.csv', nrows = 100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data pre-processing parameters\n",
    "max_fare = 200\n",
    "max_seats = 8\n",
    "max_dist = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define useful functions\n",
    "def norm(x):\n",
    "    return (x -x.mean()) / x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess training data\n",
    "train = raw_train\n",
    "\n",
    "# Remove any data with invalid entries\n",
    "train = train.dropna(how = 'any', axis = 'rows')\n",
    "\n",
    "# Extract year, hour, and city-block distance\n",
    "train = train.assign(year = train.pickup_datetime.str[:4].astype(int))\n",
    "train = train.assign(hour = train.pickup_datetime.str[11:13].astype(int))\n",
    "train = train.assign(distance =  abs(train.dropoff_latitude-train.pickup_latitude) + abs(train.dropoff_longitude-train.pickup_longitude))\n",
    "\n",
    "# Remove outliers\n",
    "train = train[(train.fare_amount > 0) & (train.fare_amount <= max_fare)]\n",
    "train = train[(train.passenger_count > 0) & (train.passenger_count <= max_seats)]\n",
    "train = train[(train.distance < max_dist)]\n",
    "\n",
    "# Separate input & output variables\n",
    "#x_train = train[['passenger_count', 'year', 'hour', 'distance', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']]\n",
    "x_train = train[['passenger_count', 'year', 'hour', 'distance']]\n",
    "y_train = train[['fare_amount']]\n",
    "\n",
    "# Normalize training data set\n",
    "x_train = norm(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0005 cost= 206.532699585\n",
      "Epoch: 0010 cost= 182.227478027\n",
      "Epoch: 0015 cost= 142.903442383\n",
      "Epoch: 0020 cost= 86.777450562\n",
      "Epoch: 0025 cost= 49.410781860\n",
      "Epoch: 0030 cost= 35.083229065\n",
      "Epoch: 0035 cost= 29.718919754\n",
      "Epoch: 0040 cost= 27.902368546\n",
      "Epoch: 0045 cost= 27.385858536\n",
      "Epoch: 0050 cost= 27.257904053\n",
      "Optimization Complete!\n",
      "Mean square error = 27.257904\n"
     ]
    }
   ],
   "source": [
    "## Multiple layers\n",
    "tf.reset_default_graph() \n",
    "# Network Parameters\n",
    "learning_rate = 0.001\n",
    "epochs = 50\n",
    "print_steps = 5\n",
    "\n",
    "n_samples = x_train.shape[0]\n",
    "n_params = x_train.shape[1]\n",
    "\n",
    "# Tensor placeholders\n",
    "X = tf.placeholder(tf.float32, shape = [None, n_params])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "\n",
    "# Model variables\n",
    "W1 = tf.get_variable(\"weight1\", shape=[n_params, 7],\n",
    "                    initializer=tf.glorot_uniform_initializer())\n",
    "b1 = tf.get_variable(\"bias1\", shape=[7],\n",
    "                    initializer=tf.constant_initializer(0.1))\n",
    "\n",
    "W2 = tf.get_variable(\"weight2\", shape=[7, 17],\n",
    "                    initializer=tf.glorot_uniform_initializer())\n",
    "b2 = tf.get_variable(\"bias2\", shape=[17],\n",
    "                    initializer=tf.constant_initializer(0.1))\n",
    "\n",
    "W3 = tf.get_variable(\"weight3\", shape=[17, 21],\n",
    "                    initializer=tf.glorot_uniform_initializer())\n",
    "b3 = tf.get_variable(\"bias3\", shape=[21],\n",
    "                    initializer=tf.constant_initializer(0.1))\n",
    "\n",
    "W4 = tf.get_variable(\"weight4\", shape=[21, 11],\n",
    "                    initializer=tf.glorot_uniform_initializer())\n",
    "b4 = tf.get_variable(\"bias4\", shape=[11],\n",
    "                    initializer=tf.constant_initializer(0.1))\n",
    "\n",
    "W5 = tf.get_variable(\"weight5\", shape=[11, 1],\n",
    "                    initializer=tf.glorot_uniform_initializer())\n",
    "b5 = tf.get_variable(\"bias5\", shape=[1],\n",
    "                    initializer=tf.constant_initializer(0.1))\n",
    "\n",
    "# Initialize the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Linear model\n",
    "Y1 = tf.add(tf.matmul(X, W1), b1)\n",
    "Y2 = tf.add(tf.matmul(Y1, W2), b2)\n",
    "Y3 = tf.add(tf.matmul(Y2, W3), b3)\n",
    "Y4 = tf.add(tf.matmul(Y3, W4), b4)\n",
    "Y5 = tf.add(tf.matmul(Y4, W5), b5)\n",
    "pred = Y5\n",
    "\n",
    "# Mean squared error\n",
    "cost = tf.reduce_mean(tf.square(pred-Y))\n",
    "# Gradient descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    # Fit all training data\n",
    "    for epoch in range(epochs):\n",
    "        sess.run(optimizer, feed_dict={X: x_train, Y: y_train})\n",
    "\n",
    "        # Display log at given epoch interval\n",
    "        if (epoch+1) % print_steps == 0:\n",
    "            c = sess.run(cost, feed_dict={X: x_train, Y: y_train})\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost =\", \"{:.9f}\".format(c))\n",
    "            \n",
    "\n",
    "    print(\"Optimization Complete!\")\n",
    "    \n",
    "    training_cost = sess.run(cost, feed_dict={X: x_train, Y: y_train})\n",
    "    print(\"Mean square error =\", training_cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
